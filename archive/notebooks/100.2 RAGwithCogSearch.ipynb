{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG pattern with Azure OpenAI and Cognitive Search Vector\n",
    "This code demonstrates how to use Azure Cognitive Search with OpenAI and Azure Python SDK leveraging the RAG pattern for context specific answers from LLM\n",
    "\n",
    "## Prerequisites\n",
    "1. To run the code, install the following packages. Please use the latest pre-release version `pip install azure-search-documents==11.4.0b6`.\n",
    "2. The [1.0 CreateKnowledgeBaseWithCogSearch notebook](1.0%20CreateKnowledgeBaseWithCogSearch.ipynb) has been run first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- > ! pip install azure-search-documents==11.4.0b6\n",
    "- > ! pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all the AOAI API keys and model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Got OPENAI API Key from environment variable\n",
      "AOAI setup succeeded\n"
     ]
    }
   ],
   "source": [
    "import aoai\n",
    "\n",
    "MY_AOAI_ENDPOINT = 'https://tr-non-prod-gpt4.openai.azure.com/'\n",
    "MY_AOAI_VERSION = '2023-07-01-preview'\n",
    "MY_GPT_ENGINE = 'tr-gpt4'\n",
    "MY_AOAI_EMBEDDING_ENGINE = 'tr-embedding-ada'\n",
    "\n",
    "status = aoai.setupOpenai(aoai_endpoint=MY_AOAI_ENDPOINT, \n",
    "                 aoai_version=MY_AOAI_VERSION)\n",
    "if status > 0:\n",
    "    print(\"AOAI setup succeeded\")\n",
    "else:\n",
    "    print(\"AOAI setup failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authenticate to Azure Cognitive Search and connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Got Azure Cognitive Search ADMIN API Key from environment variable\n"
     ]
    }
   ],
   "source": [
    "import cog_search\n",
    "\n",
    "cogSearchCredential = cog_search.getCogSearchCredential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "\n",
    "# The search index\n",
    "MY_COG_SEARCH_ENDPOINT = 'https://tr-docai-cog-search.search.windows.net'\n",
    "MY_COG_SEEARCH_INDEX_NAME = 'sample-azure-service-docs-index'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all other necessary search packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents import SearchClient  \n",
    "from azure.search.documents.models import Vector  \n",
    "from azure.search.documents.indexes.models import (  \n",
    "    SearchIndex,  \n",
    "    SearchField,  \n",
    "    SearchFieldDataType,  \n",
    "    SimpleField,  \n",
    "    SearchableField,  \n",
    "    SearchIndex,  \n",
    "    SemanticConfiguration,  \n",
    "    PrioritizedFields,  \n",
    "    SemanticField,  \n",
    "    SearchField,  \n",
    "    SemanticSettings,  \n",
    "    VectorSearch,  \n",
    "    VectorSearchAlgorithmConfiguration,  \n",
    ")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End user question for AOAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what does scalable storage solution integrate with?\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AOAI answer without RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: 85\n",
      "Finish Reason: stop\n",
      "Answer: Scalable storage solutions can integrate with various systems such as cloud computing platforms (like AWS, Google Cloud, Azure), databases, content management systems, virtualization platforms, data backup and recovery systems, and various enterprise applications. The integration depends on the specific storage solution and its compatibility.\n"
     ]
    }
   ],
   "source": [
    "my_prompt = [\n",
    "              {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": f\"Answer the user question. \\\n",
    "                            \\n\\nuser question: {query}\\\n",
    "                            \\nanswer:\"\n",
    "                }\n",
    "            ]      \n",
    "tokens_used, finish_reason, aoai_answer = aoai.getChatCompletion(the_engine=MY_GPT_ENGINE, \n",
    "                                                                           the_messages=my_prompt)\n",
    "print(f\"Tokens: {tokens_used}\")\n",
    "print(f\"Finish Reason: {finish_reason}\")\n",
    "print(f\"Answer: {aoai_answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AOAI answer with RAG \n",
    "\n",
    "## Perform a Hybrid Cognitive Search to get context information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Azure Table Storage\n",
      "\n",
      "Score: 0.03279569745063782\n",
      "\n",
      "Content: Azure Table Storage is a fully managed, NoSQL datastore that enables you to store and query large amounts of structured, non-relational data. It provides features like automatic scaling, schema-less design, and a RESTful API. Table Storage supports various data types, such as strings, numbers, and booleans. You can use Azure Table Storage to store and manage your data, build scalable applications, and reduce the cost of your storage. It also integrates with other Azure services, such as Azure Functions and Azure Cosmos DB.\n",
      "\n",
      "Category: Storage\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hybrid Search\n",
    "search_client = SearchClient(\n",
    "                    endpoint=MY_COG_SEARCH_ENDPOINT, \n",
    "                    index_name=MY_COG_SEEARCH_INDEX_NAME, \n",
    "                    credential=cogSearchCredential)\n",
    "  \n",
    "results = search_client.search(  \n",
    "    search_text=query,  \n",
    "    vector=aoai.generate_embedding(\n",
    "                    the_engine=MY_AOAI_EMBEDDING_ENGINE,\n",
    "                    the_text=query), \n",
    "    top_k=1,  \n",
    "    vector_fields=\"contentVector\",\n",
    "    select=[\"title\", \"content\", \"category\"],\n",
    "    top=1\n",
    ")  \n",
    "  \n",
    "for result in results:  \n",
    "    print(f\"Title: {result['title']}\\n\")  \n",
    "    print(f\"Score: {result['@search.score']}\\n\")  \n",
    "    print(f\"Content: {result['content']}\\n\")  \n",
    "    print(f\"Category: {result['category']}\\n\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Engineering step to Ground Prompt with the above context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: 158\n",
      "Finish Reason: stop\n",
      "Answer: Azure Table Storage integrates with other Azure services, such as Azure Functions and Azure Cosmos DB.\n"
     ]
    }
   ],
   "source": [
    "my_context = result['content']\n",
    "my_prompt = [\n",
    "              {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": f\"Answer the user question from the context provided below. \\\n",
    "                            \\n\\nuser question: {query}\\\n",
    "                            \\ncontext: {my_context}\\\n",
    "                            \\nanswer:\"\n",
    "                }\n",
    "            ]      \n",
    "tokens_used, finish_reason, aoai_answer = aoai.getChatCompletion(the_engine=MY_GPT_ENGINE, \n",
    "                                                                           the_messages=my_prompt)\n",
    "print(f\"Tokens: {tokens_used}\")\n",
    "print(f\"Finish Reason: {finish_reason}\")\n",
    "print(f\"Answer: {aoai_answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
