{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3630c235-f891-4874-bd0a-5277d4d6aa82",
   "metadata": {},
   "source": [
    "# Reasoning\n",
    "\n",
    "Chain of thought etc.\n",
    "\n",
    "## Setup\n",
    "#### Follow [README](https://github.com/tirtho/open-ai/blob/main/README.md) and perform setup before running the notebooks\n",
    "\n",
    "Reference : \n",
    "- [Azure Open AI](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/overview)\n",
    "\n",
    "#### Load the API key and relevant Python libaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "39689e67",
   "metadata": {
    "height": 132
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Got OPENAI API Key from environment variable\n",
      "Connecting to Open AI returned status as True\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import sys\n",
    "\n",
    "from azure_openai_setup import get_openai_client, get_config_from_os_env, get_chat_completion\n",
    "\n",
    "THE_MODEL = 'gpt-35-turbo-16k'\n",
    "endpoint, key, version = get_config_from_os_env()\n",
    "#print(f\"{endpoint}, {key}, {version}\")\n",
    "status, client = get_openai_client(aoai_endpoint = endpoint, \n",
    "                                   aoai_api_key = key, \n",
    "                                   aoai_version = version\n",
    "                                  )\n",
    "print(f\"Connecting to Open AI returned status as {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d2fdfa-c99f-4750-8574-dba7712cd7f0",
   "metadata": {},
   "source": [
    "## Math Word Problem\n",
    "\n",
    "Took the probability example from [here](https://math.stackexchange.com/questions/334516/balls-of-3-colours-in-a-bag-probability)\n",
    "\n",
    "First try, we are just passing the formula in the abstract example. \n",
    "So, we are not providing the detailed Chain of Thought steps.\n",
    "Let's see if the LLM model was able to answer correctly without detailed Chain of Thought!\n",
    "\n",
    "The correct answer is 3/44. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0f3b49b",
   "metadata": {
    "height": 200
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To find the probability that all three balls are of the same color, we need to find the probability of picking 3 red balls, 3 green balls, or 3 blue balls.\n",
      "\n",
      "The probability of picking 3 red balls is (3/12) * (2/11) * (1/10) = 1/220.\n",
      "\n",
      "The probability of picking 3 green balls is (4/12) * (3/11) * (2/10) = 1/165.\n",
      "\n",
      "The probability of picking 3 blue balls is (5/12) * (4/11) * (3/10) = 1/88.\n",
      "\n",
      "Therefore, the probability that all three balls are of the same color is (1/220) + (1/165) + (1/88) = 11/660.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "There are 12 tennis balls in a bag. 3 of them are red, 4 of them \\\n",
    "are green, and 5 of them are blue. John randomly picks 3 balls \\\n",
    "at the same time. \\\n",
    "What is the probability that all three balls are of the same color? \\\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "my_prompt = [\n",
    "              {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": f\"{prompt}\"\n",
    "                }\n",
    "              ]      \n",
    "tokens_used, finish_reason, completion = get_chat_completion(\n",
    "                                                the_client=client, \n",
    "                                                the_model=THE_MODEL,\n",
    "                                                the_messages=my_prompt)\n",
    "#print(f\"Completion: {completion}\\nTokens used: {tokens_used}\\nFinish Reason: {finish_reason}\")\n",
    "print(f'{completion}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb5c44a",
   "metadata": {},
   "source": [
    "#### Now I add the Chain of Thought Reasoning\n",
    "I provide detailed steps to compute the probability.\n",
    "Let's watch if the LLM can use the Chain of Thought Reasoning to compute the correct answer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff499f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of ways to pick 3 balls from 12 is C(12,3) = 12!/(3!(12-3)!) = 220.\n",
      "\n",
      "The number of ways to pick 3 red balls is C(3,3) = 1.\n",
      "The number of ways to pick 3 green balls is C(4,3) = 4.\n",
      "The number of ways to pick 3 blue balls is C(5,3) = 10.\n",
      "\n",
      "So, the probability that all three balls are of the same color is (1+4+10)/220 = 15/220 = 3/44.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "The toy store has N kites. \\\n",
    "Of these, p are white, q are beige, \\\n",
    "and r are orange. Troy bought x kites randomly from the store at the same time. \\\n",
    "What is the probability Troy bought all kites of the same color? \\\n",
    "\n",
    "Answer: \n",
    "Y! = Y * (Y -1) * (Y - 2)... 3*2*1\n",
    "C(U,v) = U!/(v!(U-v)!)\n",
    "Probability of picking x kites from the p white kites = C(p,x)\n",
    "Probability of picking x kites from the q beige kites = C(q,x)\n",
    "Probability of picking x kites from the r orange kites = C(r,x)\n",
    "Probability of picking x kites from the N kites = C(N,x)\n",
    "\n",
    "So, the answer is (C(p,x) + C(q,x) + C(r,x))/C(N,x)\n",
    "\n",
    "There are 12 tennis balls in a bag. 3 of them are red, 4 of them \\\n",
    "are green, and 5 of them are blue. John randomly picks 3 balls \\\n",
    "at the same time. \\\n",
    "What is the probability that all three balls are of the same color? \\\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "my_prompt = [\n",
    "              {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": f\"{prompt}\"\n",
    "                }\n",
    "              ]      \n",
    "tokens_used, finish_reason, completion = get_chat_completion(\n",
    "                                                the_client=client, \n",
    "                                                the_model=THE_MODEL,\n",
    "                                                the_messages=my_prompt)\n",
    "#print(f\"Completion: {completion}\\nTokens used: {tokens_used}\\nFinish Reason: {finish_reason}\")\n",
    "print(f'{completion}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ba673f",
   "metadata": {},
   "source": [
    "## Understanding Data Problem\n",
    "First one below is easy! :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a9e00b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The store refused to accept the return because you exceeded the 10-day return policy. Since you purchased the shirt on 12/03/2022 and attempted to return it on 12/15/2022, it was beyond the allowed time frame for returns.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "I bought a shirt from the local retail store on 12/03/2022. \\\n",
    "I bought the wrong size and want to return it to the store for a refund. \\\n",
    "The store has a 10 day return policy. \\\n",
    "I went to return it on 12/15/2022. \\\n",
    "Why did the store refuse to accept the return?\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "my_prompt = [\n",
    "              {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": f\"{prompt}\"\n",
    "                }\n",
    "              ]      \n",
    "tokens_used, finish_reason, completion = get_chat_completion(\n",
    "                                                the_client=client, \n",
    "                                                the_model=THE_MODEL,\n",
    "                                                the_messages=my_prompt)\n",
    "#print(f\"Completion: {completion}\\nTokens used: {tokens_used}\\nFinish Reason: {finish_reason}\")\n",
    "print(f'{completion}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a156cc",
   "metadata": {},
   "source": [
    "#### This one may not return the right answer.\n",
    "Right answer is 05/22/2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45972ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 days from tomorrow would be 05/12/2023.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "The release date of the product was 05/01/2023, \\\n",
    "but it was delayed by 10 days to today. \\\n",
    "What is 10 days from tomorrow in the MM/DD/YYYY format?\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "my_prompt = [\n",
    "              {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": f\"{prompt}\"\n",
    "                }\n",
    "              ]      \n",
    "tokens_used, finish_reason, completion = get_chat_completion(\n",
    "                                                the_client=client, \n",
    "                                                the_model=THE_MODEL,\n",
    "                                                the_messages=my_prompt)\n",
    "#print(f\"Completion: {completion}\\nTokens used: {tokens_used}\\nFinish Reason: {finish_reason}\")\n",
    "print(f'{completion}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486f5431",
   "metadata": {},
   "source": [
    "#### Let's add some steps and hope it understands the chain of reasoning\n",
    "Right answer is 05/22/2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ce95889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original date = 05/01/2023\n",
      "Today = Original date + 10 days = 05/01/2023 + 10 days = 05/11/2023\n",
      "Tomorrow = Today + 1 day = 05/11/2023 + 1 day = 05/12/2023\n",
      "Answer = 10 days from Tomorrow = 05/12/2023 + 10 days = 05/22/2023\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Date of my presentation was on 01/01/2022. \\\n",
    "It got deplayed by 5 days. \\\n",
    "Now that is today! \\\n",
    "So, what date is 7 days from tomorrow in the MM/DD/YYYY format?\n",
    "\n",
    "Answer: \n",
    "Original date = 01/01/2022\n",
    "Today = Original date + 5 days = 01/01/2022 + 5 days = 01/06/2022\n",
    "Tomorrow = Today + 1 day = 01/06/2022 + 1 day = 01/07/2022\n",
    "Answer = 7 days from Tomorrow = 01/07/2022 + 7 days = 01/14/2022\n",
    "\n",
    "The release date of the product was 05/01/2023, \\\n",
    "but it was delayed by 10 days to today. \\\n",
    "What is 10 days from tomorrow in the MM/DD/YYYY format?\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "my_prompt = [\n",
    "              {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": f\"{prompt}\"\n",
    "                }\n",
    "              ]      \n",
    "tokens_used, finish_reason, completion = get_chat_completion(\n",
    "                                                the_client=client, \n",
    "                                                the_model=THE_MODEL,\n",
    "                                                the_messages=my_prompt)\n",
    "#print(f\"Completion: {completion}\\nTokens used: {tokens_used}\\nFinish Reason: {finish_reason}\")\n",
    "print(f'{completion}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
