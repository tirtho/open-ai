{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Content Safety\n",
    "\n",
    "\n",
    "Azure Content Safety APIs are used with API key. A secured way for developers to get these keys is from Azure Key Vault. This pattern eliminates the need to store the secrets in your code.\n",
    "\n",
    "#### Follow [README](https://github.com/tirtho/open-ai/blob/main/README.md) and perform setup before running the notebooks\n",
    "\n",
    "Reference : \n",
    "- [Azure Open AI](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/overview)\n",
    "- [Azure Content Safety API](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/contentsafety/azure-ai-contentsafety)\n",
    "\n",
    "#### Load the API key and relevant Python libaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Azure Content Safety Credentials from Azure Key Vault with Azure CLI Auth\n"
     ]
    }
   ],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.contentsafety import ContentSafetyClient\n",
    "\n",
    "from azure_content_safety_setup import set_content_safety_config\n",
    "\n",
    "key, endpoint = set_content_safety_config()\n",
    "credential = AzureKeyCredential(key)\n",
    "client = ContentSafetyClient(endpoint, credential)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze text <span style=\"color:red\">without blocklists</span>\n",
    "Notice the Content Safety system does not detect anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content Safety Results:\n",
      "\tHate severity: 0\n",
      "\tSelfHarm severity: 0\n",
      "\tViolence severity: 0\n",
      "\tSexual severity: 0\n"
     ]
    }
   ],
   "source": [
    "from azure.core.exceptions import HttpResponseError\n",
    "from azure.ai.contentsafety.models import AnalyzeTextOptions, TextCategory\n",
    "\n",
    "request = AnalyzeTextOptions(text=\"I will kil'ya all, you mo**ns.\", \n",
    "                             categories=[TextCategory.HATE, \n",
    "                                         TextCategory.SELF_HARM, \n",
    "                                         TextCategory.VIOLENCE,\n",
    "                                         TextCategory.SEXUAL]\n",
    "                            )\n",
    "try:\n",
    "    response = client.analyze_text(request)\n",
    "except HttpResponseError as e:\n",
    "    print(\"Analyze text failed.\")\n",
    "    if e.error:\n",
    "        print(f\"Error code: {e.error.code}\")\n",
    "        print(f\"Error message: {e.error.message}\")\n",
    "        raise\n",
    "    print(e)\n",
    "    raise\n",
    "\n",
    "text = 'Content Safety Results:'\n",
    "# Check the severity (0 to 6)\n",
    "if response.hate_result:\n",
    "    text = text + \"\\n\\tHate severity: {}\".format(response.hate_result.severity)\n",
    "if response.self_harm_result:\n",
    "    text = text + \"\\n\\tSelfHarm severity: {}\".format(response.self_harm_result.severity)\n",
    "if response.violence_result:\n",
    "    text = text + \"\\n\\tViolence severity: {}\".format(response.violence_result.severity)\n",
    "if response.sexual_result:\n",
    "    text = text + \"\\n\\tSexual severity: {}\".format(response.sexual_result.severity)\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read lines from a file and check for content safety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[safe_content.txt]:[0]:You are awesome.\n",
      "\n",
      "Content Safety Results:\n",
      "\tHate severity: 0\n",
      "\tSelfHarm severity: 0\n",
      "\tViolence severity: 0\n",
      "\tSexual severity: 0\n",
      "[safe_content.txt]:[1]:The world is great.\n",
      "\n",
      "Content Safety Results:\n",
      "\tHate severity: 0\n",
      "\tSelfHarm severity: 0\n",
      "\tViolence severity: 0\n",
      "\tSexual severity: 0\n"
     ]
    }
   ],
   "source": [
    "from azure.core.exceptions import HttpResponseError\n",
    "from azure.ai.contentsafety.models import AnalyzeTextOptions, TextCategory\n",
    "import os\n",
    "\n",
    "from azure_content_safety_setup import get_content_safety\n",
    "\n",
    "text_file = 'safe_content.txt'\n",
    "text_path = os.path.join(os.getcwd(),'./data/', text_file)\n",
    "\n",
    "# Read file line by line and check for content safety\n",
    "i = 0\n",
    "with open(text_path) as f:\n",
    "    for line in f:\n",
    "        print(\"[%s]:[%s]:%s\" %(text_file, i, line))\n",
    "        # calling my function to do the job\n",
    "        result = get_content_safety(client=client, text_input=line)\n",
    "        print(result)\n",
    "        i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add a block list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Blocklist created or updated: \n",
      "Created Block list name: TR_Custom_Blocked_Text_List\n"
     ]
    }
   ],
   "source": [
    "from azure_content_safety_setup import add_or_update_block_list\n",
    "\n",
    "MY_BLOCK_LIST = 'TR_Custom_Blocked_Text_List'\n",
    "MY_BLOCK_LIST_DESCRIPTION = 'TRs fun list of blocked text strings for testing and demo of the Azure Content Safety APIs'\n",
    "added_block_list = add_or_update_block_list(client = client, \n",
    "                                            block_list_name = MY_BLOCK_LIST, \n",
    "                                            block_list_description = MY_BLOCK_LIST_DESCRIPTION)\n",
    "print(\"Created Block list name: %s\" %(added_block_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add blocked text strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Add block items failed: \n",
      "Error code: InvalidRequestBody\n",
      "Error message: Some items already exist in list TR_Custom_Blocked_Text_List. items: [m0**ns,kil'ya,f**king]. | Request Id: b3080edf-ff8e-4c11-9d7b-54954f4291cd, Timestamp: 2023-06-15T12:58:19Z.\n",
      "(InvalidRequestBody) Some items already exist in list TR_Custom_Blocked_Text_List. items: [m0**ns,kil'ya,f**king]. | Request Id: b3080edf-ff8e-4c11-9d7b-54954f4291cd, Timestamp: 2023-06-15T12:58:19Z.\n",
      "Code: InvalidRequestBody\n",
      "Message: Some items already exist in list TR_Custom_Blocked_Text_List. items: [m0**ns,kil'ya,f**king]. | Request Id: b3080edf-ff8e-4c11-9d7b-54954f4291cd, Timestamp: 2023-06-15T12:58:19Z.\n",
      "Blocked Text items: FAILED\n"
     ]
    }
   ],
   "source": [
    "from azure_content_safety_setup import add_blocked_items\n",
    "\n",
    "my_blocked_text_array = [\"kil'ya\", \"f**king\", \"m0**ns\"]\n",
    "added_text_list = add_blocked_items(\n",
    "                        client = client, \n",
    "                        block_list_name = MY_BLOCK_LIST, \n",
    "                        block_text_array = my_blocked_text_array\n",
    "                    )\n",
    "print(\"Blocked Text items: %s\" %(added_text_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze text <span style=\"color:red\">with block list</span>\n",
    "Notice now it is detecting inappropriate content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content Safety Results (blank if none found):\n",
      "  Blocklist match results: \n",
      "\tBlock item hit in text, Offset=7, Length=6\n",
      "\tBlocklistName: TR_Custom_Blocked_Text_List, BlockItemId: 1f58ef20-0968-4de6-9231-37d5cedf532e\n",
      "\tBlockItemText: kil'ya\n"
     ]
    }
   ],
   "source": [
    "from azure_content_safety_setup import get_content_safety_custom\n",
    "\n",
    "result = get_content_safety_custom(client = client, block_list_names = [MY_BLOCK_LIST], text_input = \"I will kil'ya\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Content Safety Results in file C:\\Users\\tibarar\\OneDrive - Microsoft\\Desktop\\MyProjects\\open-ai\\ResponsibleAI\\./data/image.jpg:\n",
      "\tHate severity: 0\n",
      "\tSelfHarm severity: 0\n",
      "\tViolence severity: 2\n",
      "\tSexual severity: 0\n"
     ]
    }
   ],
   "source": [
    "from azure_content_safety_setup import get_image_safety\n",
    "import os\n",
    "\n",
    "image_file = 'image.jpg'\n",
    "image_path = os.path.join(os.getcwd(),'./data/', image_file)\n",
    "\n",
    "result = get_image_safety(client = client, image_filepath = image_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
