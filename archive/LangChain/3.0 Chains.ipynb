{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Chains\n",
    "\n",
    "Complex applications require chaining LLMs either with each other or with other components.\n",
    "\n",
    "## Setup\n",
    "#### Follow [README](https://github.com/tirtho/open-ai/blob/main/README.md) and perform setup before running the notebooks\n",
    "\n",
    "Reference : \n",
    "- [Azure Open AI](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/overview)\n",
    "- [LangChain home page](https://python.langchain.com/docs/get_started/introduction.html)\n",
    "\n",
    "#### Load the API key and relevant Python libaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1685732595135
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got Azure OpenAI Credentials from Azure Key Vault with Azure CLI Auth\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import sys\n",
    "\n",
    "from azure_openai_setup import set_openai_config, get_openai_global_config_parameters \n",
    "\n",
    "set_openai_config()\n",
    "\n",
    "theOpenAIParams, modelName, modelDeploymentName = get_openai_global_config_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain Simple example\n",
    "Using LLMChain, which is the most basic block chain.\n",
    "\n",
    "- Takes a prompt template, \n",
    "- Formats it with user input.\n",
    "- Returns response from an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import AzureChatOpenAI\n",
    "\n",
    "# The openai.<variables> are already filled up by the above \n",
    "# set_openai_config() helper function called from above cell.\n",
    "# Check that function for more details\n",
    "\n",
    "azureChatClient = AzureChatOpenAI(\n",
    "            openai_api_key = theOpenAIParams.api_key,\n",
    "            openai_api_base = theOpenAIParams.api_base,\n",
    "            openai_api_version = theOpenAIParams.api_version,\n",
    "            deployment_name = modelDeploymentName,\n",
    "            temperature=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Protect your ride and your peace of mind with our comprehensive auto insurance coverage.\"\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Generate a single line marketing campaign for the {product} \\\n",
    "of a {company} \\\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "                input_variables = ['product', 'company'],\n",
    "                template = template\n",
    "            )\n",
    "chain = LLMChain(llm = azureChatClient, prompt = prompt)\n",
    "print(chain.run({\n",
    "    'company': 'Property & Casualty Insurance company',\n",
    "    'product': 'auto insurance'\n",
    "}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Chain\n",
    "\n",
    "More complex chains that involve multiple inputs and multiple final outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an LLMChain to write a synopsis given a title of a play and the era it is set in.\n",
    "template = \"\"\"You are a playwright. Given the title of play and the era it is set in, it is your job to write a synopsis for that title.\n",
    "\n",
    "Title: {title}\n",
    "Era: {era}\n",
    "Playwright: This is a synopsis for the above play:\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"title\", 'era'], template=template)\n",
    "synopsis_chain = LLMChain(llm=azureChatClient, prompt=prompt_template, output_key=\"synopsis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an LLMChain to write a review of a play given a synopsis.\n",
    "template = \"\"\"You are a play critic from the New York Times. Given the synopsis of play, it is your job to write a review for that play.\n",
    "\n",
    "Play Synopsis:\n",
    "{synopsis}\n",
    "Review from a New York Times play critic of the above play:\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"synopsis\"], template=template)\n",
    "review_chain = LLMChain(llm=azureChatClient, prompt=prompt_template, output_key=\"review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the overall chain where we run these two chains in sequence.\n",
    "from langchain.chains import SequentialChain\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[synopsis_chain, review_chain],\n",
    "    input_variables=[\"era\", \"title\"],\n",
    "    # Here we return multiple variables\n",
    "    output_variables=[\"synopsis\", \"review\"],\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'title': 'Tragedy at sunset on the beach',\n",
       " 'era': 'Victorian England',\n",
       " 'synopsis': \"In the height of Victorian England, a young noblewoman named Felicity falls deeply in love with a commoner, William, who works as a fisherman on the coast. Despite the disapproval of her family and society, Felicity follows her heart and runs away with William to start a new life together. They settle in a small seaside town where they build a new home and start a family. \\n\\nHowever, their perfect life is soon shattered when a terrible tragedy strikes: while Felicity and William's children are playing on the beach at sunset, a sudden storm brews and their youngest child is swept away by the raging waves. In their grief and desperation to find their child, Felicity and William's relationship begins to unravel, and they are forced to confront the reality of their vastly different backgrounds and the societal pressures that have plagued their relationship from the start. \\n\\nAs their tragedy unfolds, the play delves into themes of classism, societal expectations, and the power of love in the face of tragedy. The question remains: will Felicity and William's love be strong enough to overcome the obstacles that stand in their way, or will the tragedy at sunset on the beach tear them apart forever?\",\n",
       " 'review': 'In \"Sunset on the Beach,\" playwrights have crafted a compelling story that explores deep themes of love, loss, and societal constraints. The play\\'s Victorian setting adds an air of elegance and sophistication to the narrative, and the complex characters of Felicity and William draw the audience into their world and their struggle.\\n\\nThe first half of the play is enchanting, as we see the two protagonists falling deeply in love and following their hearts against society\\'s expectations. However, the arrival of tragedy in the second act changes everything and serves as a catalyst for the play\\'s exploration of classism and societal pressures on relationships.\\n\\nThe acting in this production is top-notch, with the leads convincingly portraying the pain and desperation of a couple torn apart by grief and societal expectations. The play\\'s themes are universal and resonate with the audience long after the show has ended.\\n\\nOverall, \"Sunset on the Beach\" is a well-crafted production that will leave audiences thinking and talking about the power of love and the impact of societal expectations on relationships. It is a must-see for theater enthusiasts looking for a thoughtful, emotionally charged experience.'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_chain({\"title\":\"Tragedy at sunset on the beach\", \"era\": \"Victorian England\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Router Chain\n",
    "\n",
    "Create a chain that dynamically selects the next chain to use for a given input.\n",
    "\n",
    "Router chains are made up of two components:\n",
    "\n",
    "- The RouterChain itself (responsible for selecting the next chain to call)\n",
    "- destination_chains: chains that the router chain can route to\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the prompts, templates and the destination_chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. You are great at answering math questions. \\\n",
    "You are so good because you are able to break down hard problems into their component parts, \\\n",
    "answer the component parts, and then put them together to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"physics\",\n",
    "        \"description\": \"Good for answering questions about physics\",\n",
    "        \"prompt_template\": physics_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\",\n",
    "        \"description\": \"Good for answering math questions\",\n",
    "        \"prompt_template\": math_template,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"input\"])\n",
    "    chain = LLMChain(llm=azureChatClient, prompt=prompt)\n",
    "    destination_chains[name] = chain\n",
    "default_chain = ConversationChain(llm=azureChatClient, output_key=\"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the LLMRouterChain to determine how to route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE\n",
    "\n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)\n",
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=destinations_str)\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "router_chain = LLMRouterChain.from_llm(azureChatClient, router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = MultiPromptChain(\n",
    "    router_chain=router_chain,\n",
    "    destination_chains=destination_chains,\n",
    "    default_chain=default_chain,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the user input against the router now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "physics: {'input': 'What is black body radiation?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Black body radiation refers to the electromagnetic radiation emitted by a perfect black body, which is an object that absorbs all radiation that falls on it and emits radiation with a characteristic thermal spectrum. The spectrum of black body radiation depends only on the temperature of the object and is described by Planck's law. Black body radiation is important in many areas of physics, including thermodynamics, quantum mechanics, and astrophysics. It also has practical applications, such as in the design of incandescent light bulbs and infrared cameras.\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"What is black body radiation?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "math: {'input': 'What is the first prime number greater than 40 such that one plus the prime number is divisible by 3'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "?\n",
      "\n",
      "To solve this problem, we first need to identify which prime numbers are greater than 40. The primes greater than 40 are 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97.\n",
      "\n",
      "Next, we need to check which of these primes satisfies the condition that one plus the prime number is divisible by 3. To do this, we can use the fact that if a number is divisible by 3, then the sum of its digits is also divisible by 3.\n",
      "\n",
      "Adding 1 to each of these primes, we get:\n",
      "\n",
      "42 → 4 + 2 = 6 (divisible by 3)\n",
      "44 → 4 + 4 = 8 (not divisible by 3)\n",
      "48 → 4 + 8 = 12 (divisible by 3)\n",
      "54 → 5 + 4 = 9 (divisible by 3)\n",
      "\n",
      "So the first prime number greater than 40 that satisfies the condition is 43, since 1 + 43 = 44, which is not divisible by 3, but 43 itself is prime. Therefore, the answer is 43.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    chain.run(\n",
    "        \"What is the first prime number greater than 40 such that one plus the prime number is divisible by 3\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EmbeddingRouterChain\n",
    "Uses embeddings and similarity to route between destination chains. \n",
    "\n",
    "[Details](https://python.langchain.com/docs/modules/chains/foundational/router#embeddingrouterchain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sequential Chain\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
